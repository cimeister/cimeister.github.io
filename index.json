
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":["admin"],"categories":null,"content":"I’m a PhD student in Computer Science with Professor Ryan Cotterell at ETH Zürich, supported by a Google PhD Fellowship. I am passionate about the general application of statistics and information theory to natural language processing. A large portion of my research in the last years has been on natural language generation—specifically, on decoding methods for probabilistic models. In my free time, I go rock climbing, trail running, and just about everything that falls in between the two. You can check out some of my adventures on my husband’s instagram. I am a proud member of the Akademischer Alpenclub Zürich.\nI have had the privelage of serving as the advisor for several MSc students during the writing of their theses. Some of these theses have turned into published works.\nLuca Malugatti: Divergence functions for Natural Language Generation Liam van der Poel: Mutual Information for Identifying and Preventing Hallucinations in Abstractive Summarization (EMNLP Paper) Andy Buinovskij: Advanced Smoothing Techniques for Training Neural Language Model Samuel Pullely: Text Detoxification using Pre-Trained Language Models and Plug-and-Play Generation Methods Franz Knobel: Probing Language Models With Topic Models Gian Wiher: A Taxonomy of Decoding Schemes for Language Generation Models (TACL Paper) Luca Disse: Exploring the Inductive Biases of Sparsity-Inducing Learning Algorithms for Language Modeling Afra Amini: Causal Probing for Gender Differences in Contextual Word Representations (TACL Paper) Martina Forster: Search Errors in Morphological Inflection Generation Systems (EACL Paper) Stefan Lasov: Effects of Sparse Attention on Model Interpretability (EMNLP Paper) ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I’m a PhD student in Computer Science with Professor Ryan Cotterell at ETH Zürich, supported by a Google PhD Fellowship. I am passionate about the general application of statistics and information theory to natural language processing.","tags":null,"title":"","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://cimeister.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Liam van der Poel","Ryan Cotterell","Clara Meister"],"categories":[],"content":"","date":1669852800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668975466,"objectID":"d5b4dbf169cd4b3e4b3998bae0bcb3a2","permalink":"https://cimeister.github.io/publication/vanderpoelal-emnlp-22/","publishdate":"2022-11-20T23:29:36.464306Z","relpermalink":"/publication/vanderpoelal-emnlp-22/","section":"publication","summary":"Despite significant progress in the quality of language generated from abstractive summarization models, these models still exhibit the tendency to hallucinate, i.e., output content not supported by the source document. A number of works have tried to fix—or at least uncover the source of—the problem with limited success. In this paper, we identify a simple criterion under which models are significantly more likely to assign more probability to hallucinated content during generation: high model uncertainty. This finding offers a potential explanation for hallucinations: models default to favoring text with high marginal probability, i.e., high-frequency occurrences in the training set, when uncertain about a continuation. It also motivates possible routes for real-time intervention during decoding to prevent such hallucinations. We propose a decoding strategy that switches to optimizing for pointwise mutual information of the source and target token—rather than purely the probability of the target token—when the model exhibits uncertainty. Experiments on the XSUM dataset show that our method decreases the probability of hallucinated tokens while maintaining the ROUGE and BERTS scores of top-performing decoding strategies.","tags":[],"title":"Mutual Information and Hallucinations in Abstractive Summarization","type":"publication"},{"authors":["Clara Meister","Tiago Pimentel","Thomas Hikaru Clark","Ryan Cotterell","Roger P. Levy"],"categories":null,"content":"","date":1651363200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1651363200,"objectID":"d4a47aa546801b1900049bdbba27569c","permalink":"https://cimeister.github.io/publication/meisteral-acl-22-b/","publishdate":"2022-05-23T14:37:53.504503Z","relpermalink":"/publication/meisteral-acl-22-b/","section":"publication","summary":"","tags":null,"title":"Analyzing Wrap-Up Effects through an Information-Theoretic Lens","type":"publication"},{"authors":["Aryaman Arora","Clara Isabel Meister","Ryan Cotterell"],"categories":null,"content":"","date":1651363200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1651363200,"objectID":"acee213decb79795ab9d2e135dbc8655","permalink":"https://cimeister.github.io/publication/aroraal-acl-22/","publishdate":"2022-05-23T14:37:53.901302Z","relpermalink":"/publication/aroraal-acl-22/","section":"publication","summary":"","tags":null,"title":"Estimating the Entropy of Linguistic Distributions","type":"publication"},{"authors":["Clara Isabel Meister","Gian Wiher","Tiago Pimentel","Ryan Cotterell"],"categories":null,"content":"","date":1651363200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1651363200,"objectID":"ba3944c5206a4072eb9370c945ec44ee","permalink":"https://cimeister.github.io/publication/meisteral-acl-22-a/","publishdate":"2022-05-23T14:37:53.315448Z","relpermalink":"/publication/meisteral-acl-22-a/","section":"publication","summary":"","tags":null,"title":"On the probability–quality paradox in language generation generation","type":"publication"},{"authors":["Tiago Pimentel\\*","Clara Meister\\*","Ryan Cotterell"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668986973,"objectID":"53e500c2c3776a5f90ff8a75471d9bbf","permalink":"https://cimeister.github.io/publication/pimentelal-arxiv-22/","publishdate":"2022-11-20T23:29:33.133493Z","relpermalink":"/publication/pimentelal-arxiv-22/","section":"publication","summary":"While probabilistic language generators have improved dramatically over the last few years, the automatic evaluation metrics used to assess them have not kept pace with this progress. In the domain of language generation, a good metric must correlate highly with human judgements. Yet, with few exceptions, there is a lack of such metrics in the literature. In this work, we analyse the general paradigm of language generator evaluation. We first discuss the computational and qualitative issues with using automatic evaluation metrics that operate on probability distributions over strings, the backbone of most language generators. We then propose the use of distributions over clusters instead, where we cluster strings based on their text embeddings (obtained from a pretrained language model). While we find the biases introduced by this substitution to be quite strong, we observe that, empirically, this methodology leads to metric estimators with higher correlation with human judgements, while simultaneously reducing estimator variance. We finish the paper with a probing analysis, which leads us to conclude that -- by encoding syntactic- and coherence-level features of text, while ignoring surface-level features -- these clusters may simply be better equipped to evaluate state-of-the-art language models.","tags":[],"title":"Cluster-based Evaluation of Automatically Generated Text","type":"publication"},{"authors":["Clara Meister","Tiago Pimentel","Gian Wiher","Ryan Cotterell"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645098248,"objectID":"f6ecf98c23ef71be8ac8e54b0483bc53","permalink":"https://cimeister.github.io/publication/meisteral-pre-22/","publishdate":"2022-02-17T11:44:08.679295Z","relpermalink":"/publication/meisteral-pre-22/","section":"publication","summary":"Today's probabilistic language generators fall short when it comes to producing coherent and fluent text, despite the fact that the underlying models perform incredibly well in terms of standard metrics such as perplexity.   This dichotomy has puzzled the language generation community for the last few years. In this work, we posit that the abstraction of natural language generation as a discrete stochastic process can provide new insights into the behavior of probabilistic language generators, e.g., why high-probability texts can be dull or repetitive. Humans use language as a means of communicating information, aiming to do so in a simultaneously efficient and error-minimizing manner; in fact, psycholinguistics research suggests humans choose each word in a string with this subconscious goal in mind. We formally define the set of strings that meet this criterion -- those for which each word has an information content close to the expected information content, i.e., the conditional entropy of our model. We then propose a simple and efficient procedure for enforcing this criterion when generating from probabilistic models, which we call locally typical sampling. Automatic and human evaluations show that, in comparison to nucleus and top-k sampling, typical sampling offers competitive performance (in both abstractive summarization and story generation) in terms of quality while consistently reducing degenerate repetitions.","tags":[],"title":"Locally Typical Sampling","type":"publication"},{"authors":["Afra Amini","Tiago Pimentel","Clara Meister","Ryan Cotterell"],"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"1144d4708c8baf1d9ecceb86ae209e7f","permalink":"https://cimeister.github.io/publication/aminial-tacl-22/","publishdate":"2022-05-23T14:37:54.411418Z","relpermalink":"/publication/aminial-tacl-22/","section":"publication","summary":"","tags":null,"title":"Naturalistic Causal Probing for Morpho-Syntax","type":"publication"},{"authors":["Gian Wiher","Clara Meister","Ryan Cotterell"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668975462,"objectID":"12482c2a89690d5ab25b1d3e14b7e83d","permalink":"https://cimeister.github.io/publication/wiheral-tacl-22/","publishdate":"2022-11-20T23:29:31.606716Z","relpermalink":"/publication/wiheral-tacl-22/","section":"publication","summary":"When generating text from probabilistic models, the chosen decoding strategy has a profound effect on the resulting text. Yet theproperties elicited by various decoding strategies do not always transfer across natural language generation tasks. For example, while mode-seeking methods like beam search perform remarkably well for machine translation, they have been observed to lead to incoherent and repetitive text in story generation. Despite such observations, the effectiveness of decod- ing strategies is often assessed on only a single task. This work—in contrast—provides a comprehensive analysis of the interaction between language generation tasks and decoding strategies. Specifically, we measure changes in attributes of generated text as a function of both decoding strategy and task using human and automatic evaluation. Our results reveal both previously observed and novel findings. For example, the nature of the diversity-quality trade-off in language generation is very task-specific; the length bias often attributed to beam search is not constant across tasks.","tags":[],"title":"On Decoding Strategies for Neural Text Generators","type":"publication"},{"authors":["Clara Meister","Afra Amini","Tim Vieira","Ryan Cotterell"],"categories":null,"content":"","date":1635724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635724800,"objectID":"ede5bfd893be4e05ff0a7039d581b5e5","permalink":"https://cimeister.github.io/publication/meisteral-emnlp-2021-b/","publishdate":"2021-08-26T07:41:17.930028Z","relpermalink":"/publication/meisteral-emnlp-2021-b/","section":"publication","summary":"","tags":null,"title":"Conditional Poisson Stochastic Beams","type":"publication"},{"authors":["Damian Pascual","Beni Egressy","Clara Meister","Ryan Cotterell","Roger Wattenhofer"],"categories":null,"content":"","date":1635724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635724800,"objectID":"b0015599f595f63fdedfe5e89dd9587e","permalink":"https://cimeister.github.io/publication/pascualal-emnlp-2021/","publishdate":"2021-08-26T07:41:18.519122Z","relpermalink":"/publication/pascualal-emnlp-2021/","section":"publication","summary":"","tags":null,"title":"Keyword2Text: A Plug-and-Play Method for Controlled Text Generation","type":"publication"},{"authors":["Tiago Pimentel","Clara Meister","Simone Teufel","Ryan Cotterell"],"categories":null,"content":"","date":1635724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635724800,"objectID":"e9de57d6c8f8ae9db1e622e48485e012","permalink":"https://cimeister.github.io/publication/pimentelal-emnlp-2021-b/","publishdate":"2021-08-26T07:41:17.780082Z","relpermalink":"/publication/pimentelal-emnlp-2021-b/","section":"publication","summary":"","tags":null,"title":"On Homophony and Rényi Entropy","type":"publication"},{"authors":["Tiago Pimentel","Clara Meister","Elizabeth Salesky","Simone Teufel","Damián Blasi","Ryan Cotterell"],"categories":null,"content":"","date":1635724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635724800,"objectID":"94cfdb7d83a8b37073f27861b0a7357c","permalink":"https://cimeister.github.io/publication/pimentelal-emnlp-2021-a/","publishdate":"2021-08-26T07:41:17.634228Z","relpermalink":"/publication/pimentelal-emnlp-2021-a/","section":"publication","summary":"","tags":null,"title":"Phone-level Uniform Information Density across and within Languages","type":"publication"},{"authors":["Clara Meister","Tiago Pimentel","Patrick Haller","Lena Jäger","Ryan Cotterell","Roger Levy"],"categories":null,"content":"","date":1635724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635724800,"objectID":"02b517b0106b183257c948b31458cc6d","permalink":"https://cimeister.github.io/publication/meisteral-emnlp-2021-a/","publishdate":"2021-08-26T07:41:17.183081Z","relpermalink":"/publication/meisteral-emnlp-2021-a/","section":"publication","summary":"","tags":null,"title":"Revisiting the Uniform Information Density Hypothesis","type":"publication"},{"authors":["Clara Meister","Martina Forster","Ryan Cotterell"],"categories":null,"content":"","date":1627862400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627862400,"objectID":"6e982c012c6a245fb72345cf796d0511","permalink":"https://cimeister.github.io/publication/meisteral2-acl-21/","publishdate":"2020-04-06T05:47:36.453048Z","relpermalink":"/publication/meisteral2-acl-21/","section":"publication","summary":"Beam search is today's go-to strategy for decoding neural sequence models. The algorithm can naturally be viewed as a subset optimization problem, albeit one where the corresponding set function does not reflect interactions between items. Empirically, this leads to sets often exhibiting high overlap, e.g., strings may differ by only a single word. Yet in use-cases that call for multiple solutions, a diverse or representative set is often desired. To address this issue, we propose a reformulation of beam search, which we call *determinantal beam search*. By posing iterations in beam search as a series of subdeterminant maximization problems, we can turn the algorithm into a diverse subset selection process. Determinantal beam search has a natural relationship to determinantal point processes (DPPs), models over sets that inherently encode intra-set interactions. In a case study, we use the string subsequence kernel to explicitly encourage n-gram coverage in text generated from a sequence model. We observe that our algorithm offers competitive performance against other diverse set generation strategies in the context of language generation, while providing a more general approach to optimizing for diversity.","tags":null,"title":"Determinantal Beam Search","type":"publication"},{"authors":["Clara Meister","Stefan Lazov","Isabelle Augenstein","Ryan Cotterell"],"categories":null,"content":"","date":1627862400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627862400,"objectID":"617124fe9e71d9e71484b4124a519a3e","permalink":"https://cimeister.github.io/publication/meisteral3-acl-21/","publishdate":"2020-04-06T05:47:36.453048Z","relpermalink":"/publication/meisteral3-acl-21/","section":"publication","summary":"Sparse attention has been claimed to increase model interpretability under the assumption that it highlights influential inputs. Yet the attention distribution is typically over representations internal to the model rather than the inputs themselves, suggesting this assumption may not have merit. We build on the recent work exploring the interpretability of attention; we design a set of experiments to help us understand how sparsity affects our ability to use attention as an explainability tool. On three text classification tasks, we verify that only a weak relationship between inputs and co-indexed intermediate representations exists -- under sparse attention and otherwise. Further, we do not find any plausible mappings from sparse attention distributions to a sparse set of influential inputs through other avenues. Rather, we observe in this setting that inducing sparsity may make it less plausible that attention can be used as a tool for understanding model behavior.","tags":null,"title":"Is Sparse Attention more Interpretable?","type":"publication"},{"authors":["Clara Meister","Ryan Cotterell"],"categories":null,"content":"","date":1627862400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627862400,"objectID":"d782c9266020e51ddc1e4a19ebec8d4b","permalink":"https://cimeister.github.io/publication/meisteral-acl-21/","publishdate":"2020-04-06T05:47:36.453048Z","relpermalink":"/publication/meisteral-acl-21/","section":"publication","summary":"We propose an alternate approach to quantifying how well language models learn natural language: we ask how well they match the *statistical tendencies* of natural language. To answer this question, we analyze whether text generated from language models exhibits the statistical tendencies present in the human-generated text on which they were trained. We provide a framework--paired with significance tests--for evaluating the fit of language models to these trends. We find that neural language models appear to learn only a subset of the tendencies considered, but align much more closely with empirical trends than proposed theoretical distributions (when present). Further, the fit to different distributions is highly-dependent on both model architecture and generation strategy. As concrete examples, text generated under the nucleus sampling scheme adheres more closely to the type--token relationship of natural language than text produced using standard ancestral sampling; text from LSTMs reflects the natural language distributions over length, stopwords, and symbols surprisingly well.","tags":null,"title":"Language Model Evaluation Beyond Perplexity","type":"publication"},{"authors":["Jason Wei","Clara Meister","Ryan Cotterell"],"categories":null,"content":"","date":1627776000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627776000,"objectID":"292e718bc257aa4df3d0f87d572098e5","permalink":"https://cimeister.github.io/publication/weial-acl-21/","publishdate":"2020-04-06T04:47:36.453048Z","relpermalink":"/publication/weial-acl-21/","section":"publication","summary":"The uniform information density (UID) hypothesis, which posits that speakers prefer utterances that distribute information uniformly across the signal, has gained substantial traction in psycholinguistics as an explanation for certain syntactic, morphological, and prosodic choices. Could we operationalize uniform information density as an inductive bias for statistical language modeling? In this paper, we augment the canonical MLE objective for training language models by encoding UID as regularization. In experiments on ten languages spanning five language families, we find that using UID regularization consistently improves perplexity in language models, having a larger effect when training data is limited. Moreover, via analysis of generated sequences, we find that UID-regularized language models are higher-entropy and produce text that is longer and more lexically diverse. Our results not only suggest that UID is a reasonable inductive bias for language modeling, but also provide an alternative validation of the UID hypothesis using modern-day NLP tools.","tags":null,"title":"A Cognitive Regularizer for Language Modeling","type":"publication"},{"authors":["Pinjia He","Clara Meister","Zhendong Su"],"categories":null,"content":"","date":1621728000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621728000,"objectID":"ab2d08afc7a886a0dc9948e5061954e5","permalink":"https://cimeister.github.io/publication/heal-icse-2021/","publishdate":"2020-09-26T06:11:17.609213Z","relpermalink":"/publication/heal-icse-2021/","section":"publication","summary":"Machine translation software has seen rapid progress in recent years due to the advancement of deep neural networks. People routinely use machine translation software in their daily lives, such as ordering food in a foreign restaurant, receiving medical diagnosis and treatment from foreign doctors, and reading international political news online. However, due to the complexity and intractability of the underlying neural networks, modern machine translation software is still far from robust and can produce poor or incorrect translations; this can lead to misunderstanding, financial loss, threats to personal safety and health, and political conflicts. To address this problem, we introduce referentially transparent inputs (RTIs), a simple, widely applicable methodology for validating machine translation software. A referentially transparent input is a piece of text that should have similar translations when used in different contexts. Our practical implementation, Purity, detects when this property is broken by a translation. To evaluate RTI, we use Purity to test Google Translate and Bing Microsoft Translator with 200 unlabeled sentences, which detected 123 and 142 erroneous translations with high precision (79.3% and 78.3%). The translation errors are diverse, including examples of under-translation, over-translation, word/phrase mistranslation, incorrect modification, and unclear logic.","tags":null,"title":"Testing Machine Translation via Referential Transparency","type":"publication"},{"authors":["Martina Forster","Clara Meister","Ryan Cotterell"],"categories":null,"content":"","date":1618790400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618790400,"objectID":"9d3d575813ecb9ecb8747e388e60d8d2","permalink":"https://cimeister.github.io/publication/forster-eacl-21/","publishdate":"2020-04-06T05:47:36.453048Z","relpermalink":"/publication/forster-eacl-21/","section":"publication","summary":"Neural sequence-to-sequence models are currently the predominant choice for language generation tasks. Yet, on word-level tasks, exact inference of these models reveals the empty string is often the global optimum. Prior works have speculated this phenomenon is a result of the inadequacy of neural models for language generation. However, in the case of morphological inflection, we find that the empty string is almost never the most probable solution under the model. Further, greedy search often finds the global optimum. These observations suggest that the poor calibration of many neural models may stem from characteristics of a specific subset of tasks rather than general ill-suitedness of such models for language generation.","tags":null,"title":"Searching for Search Errors in Neural Morphological Inflection","type":"publication"},{"authors":["Clara Meister","Tim Vieira","Ryan Cotterell"],"categories":null,"content":"","date":1604188800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604188800,"objectID":"00b67b122cbde7f1fd036ec9b7fcfec9","permalink":"https://cimeister.github.io/publication/meisteral-emnlp-20/","publishdate":"2020-09-26T06:11:17.609213Z","relpermalink":"/publication/meisteral-emnlp-20/","section":"publication","summary":"","tags":null,"title":"If Beam Search is the Answer, What was the Question?","type":"publication"},{"authors":["Clara Meister","Tim Vieira","Ryan Cotterell"],"categories":null,"content":"","date":1596240000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596240000,"objectID":"a583d975602b3880816be059c3edceb7","permalink":"https://cimeister.github.io/publication/meisteral-tacl-20/","publishdate":"2020-05-06T05:43:04.543051Z","relpermalink":"/publication/meisteral-tacl-20/","section":"publication","summary":"Decoding for many NLP tasks requires a heuristic algorithm for approximating exact search since the full search space is often intractable if not simply too large to traverse efficiently. The default algorithm for this job is beam search--a pruned version of breadth-first search--which in practice, returns better results than exact inference due to beneficial search bias. In this work, we show that standard beam search is a computationally inefficient choice for many decoding tasks; specifically, when the scoring function is a monotonic function in sequence length, other search algorithms can be used to reduce the number of calls to the scoring function (e.g., a neural network), which is often the bottleneck computation. We propose best-first beam search, an algorithm that provably returns the same set of results as standard beam search, albeit in the minimum number of scoring function calls to guarantee optimality (modulo beam size).  We show that best-first beam search can be used with length normalization and mutual information decoding, among other rescoring functions.  Lastly, we propose a memory-reduced variant of best-first beam search, which has a similar search bias in terms of downstream performance, but runs in a fraction of the time.","tags":null,"title":"Best-First Beam Search","type":"publication"},{"authors":["Shahij Gupta","Pinjia He","Clara Meister","Zhendong Su"],"categories":null,"content":"","date":1596240000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596240000,"objectID":"384629e1cca71de45576b3837e4def2c","permalink":"https://cimeister.github.io/publication/guptaal-fse-2020/","publishdate":"2020-04-06T05:47:36.453048Z","relpermalink":"/publication/guptaal-fse-2020/","section":"publication","summary":"Machine translation software has become heavily integrated into our daily lives due to the recent improvement in the performance of deep neural networks. However, machine translation software has been shown to regularly return erroneous translations, which can lead to harmful consequences such as economic loss and political conflicts. Additionally, due to the complexity of the underlying neural models, testing machine translation systems presents new challenges. To address this problem, we introduce a novel methodology called PatInv.  The main intuition behind PatInv is that sentences with different meanings should not have the same translation. Under this general idea, we provide two realizations of PatInv that given an arbitrary sentence, generate syntactically similar but semantically different sentences by: (1) replacing one word in the sentence using a masked language model or (2) removing one word or phrase from the sentence based on its constituency structure. We then test whether the returned translations are the same for the original and modified sentences. We have applied PatInv to test Google Translate and Bing Microsoft Translator using 200 English sentences. Two language settings are considered: English to Hindi (En-Hi) and  English to Chinese (En-Zh). The results show that PatInv can accurately find 308 erroneous translations in Google Translate and 223 erroneous translations in Bing Microsoft Translator, most of which cannot be found by the state-of-the-art approaches.","tags":null,"title":"Machine Translation Testing via Pathological Invariance","type":"publication"},{"authors":["Pinjia He","Clara Meister","Zhendong Su"],"categories":null,"content":"","date":1596240000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596240000,"objectID":"abe3443d10667f8ab3fc5c08adacb115","permalink":"https://cimeister.github.io/publication/heal-icse-2020/","publishdate":"2020-04-06T05:47:36.453048Z","relpermalink":"/publication/heal-icse-2020/","section":"publication","summary":"Machine translation software has increasingly been integrated into our daily lives. People routinely use machine translation for various applications, such as describing symptoms to a foreign doctor and reading political news in a foreign language. However, due to the complexity and intractability of neural machine translation (NMT) models that power modern machine translation systems, these systems are far from being robust. They can return inferior results that lead to misunderstanding, medical misdiagnoses, threats to personal safety, or political conflicts. Despite its apparent importance, validating the robustness of machine translation is very difficult and has, therefore, been much under-explored.\nTo tackle this challenge, we introduce structure-invariant testing (SIT), a novel metamorphic testing approach for validating machine translation software. Our key insight is that the translation results of “similar” source sentences should typically exhibit a similar sentence structure. Specifically, SIT (1) generates similar source sentences by substituting one word in a given sentence with semantically similar, syntactically equivalent words, and (2) represents sentence structure by syntax parse trees (obtained via constituency or dependency parsing). To evaluate SIT, we have used it to test Google Translate and Bing Microsoft Translator with 200 source sentences as input, which led to 64 and 70 buggy translations with 69.5% and 70% top-1 accuracy, respectively. The bugs are diverse, including under-translation, over-translation, incorrect modification, word/phrase mistranslation, and unclear logic, none of which could be detected via existing translation quality metrics.","tags":null,"title":"Structure-Invariant Testing for Machine Translation","type":"publication"},{"authors":["Clara Meister","Elizabeth Salesky","Ryan Cotterell"],"categories":null,"content":"","date":1593561600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593561600,"objectID":"65df8ea6f2757b720fbb48bafcdc38a4","permalink":"https://cimeister.github.io/publication/meisteral-acl-20/","publishdate":"2020-04-06T05:47:36.453048Z","relpermalink":"/publication/meisteral-acl-20/","section":"publication","summary":"Prior work has explored directly regularizing the output distributions of probabilistic models to alleviates peaky (i.e. over-confident) predictions, a common sign of overfitting. This class of techniques, of which label smoothing is one, has a deep mathematical connection to entropy regularization. Despite the consistent success of label smoothing across architectures and data sets in language generation tasks, two problems remain open; (1) there is little understanding of the underlying effects entropy regularizers have on models and (2) the full space of entropy regularization techniques is largely unexplored. We introduce a parametric family of entropy regularizers—which includes label smoothing and the confidence penalty as special cases—and use them to gain a better understanding of the relationship between the entropy of a model’s output distribution and its  performance on language generation tasks. We find that variance in model performance can be explained largely by the resulting entropy of the model’s output distribution rather than by the learning dynamics of the regularizer. Lastly, we find that label smoothing does not allow for sparsity in an output distribution, an undesirable property for language generation models, and therefore advise the use of other entropy regularization methods in its place.","tags":null,"title":"Generalized Entropy Regularization or: There's Nothing Special about Label Smoothing","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://cimeister.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"e8f8d235e8e7f2efd912bfe865363fc3","permalink":"https://cimeister.github.io/project/example/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/example/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Example Project","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"https://cimeister.github.io/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"}]