[{"authors":["admin"],"categories":null,"content":"I recently started my PhD in Computer Science with Professor Ryan Cotterell at ETH Zürich. I am passionate about the general applications of statistics and information theory to natural language processing; lately, my research has been on decoding methods for sequence models. In my free time, I like to rock climb, trail run, and search for the elusive cheap bar in Switzerland. You can check out some of my adventures on my husband\u0026rsquo;s blog: http://www.timaiken.org/blog\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://cimeister.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I recently started my PhD in Computer Science with Professor Ryan Cotterell at ETH Zürich. I am passionate about the general applications of statistics and information theory to natural language processing; lately, my research has been on decoding methods for sequence models.","tags":null,"title":"Clara Meister","type":"authors"},{"authors":["Clara Meister","Tim Vieira","Ryan Cotterell"],"categories":null,"content":"","date":1604188800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604188800,"objectID":"00b67b122cbde7f1fd036ec9b7fcfec9","permalink":"https://cimeister.github.io/publication/meisteral-emnlp-20/","publishdate":"2020-09-26T06:11:17.609213Z","relpermalink":"/publication/meisteral-emnlp-20/","section":"publication","summary":"","tags":null,"title":"If Beam Search is the Answer, What was the Question?","type":"publication"},{"authors":["Clara Meister","Ryan Cotterell","Tim Vieira"],"categories":null,"content":"","date":1596240000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596240000,"objectID":"a583d975602b3880816be059c3edceb7","permalink":"https://cimeister.github.io/publication/meisteral-tacl-20/","publishdate":"2020-05-06T05:43:04.543051Z","relpermalink":"/publication/meisteral-tacl-20/","section":"publication","summary":"Decoding for many NLP tasks requires a heuristic algorithm for approximating exact search since the full search space is often intractable if not simply too large to traverse efficiently. The default algorithm for this job is beam search--a pruned version of breadth-first search--which in practice, returns better results than exact inference due to beneficial search bias. In this work, we show that standard beam search is a computationally inefficient choice for many decoding tasks; specifically, when the scoring function is a monotonic function in sequence length, other search algorithms can be used to reduce the number of calls to the scoring function (e.g., a neural network), which is often the bottleneck computation. We propose best-first beam search, an algorithm that provably returns the same set of results as standard beam search, albeit in the minimum number of scoring function calls to guarantee optimality (modulo beam size).  We show that best-first beam search can be used with length normalization and mutual information decoding, among other rescoring functions.  Lastly, we propose a memory-reduced variant of best-first beam search, which has a similar search bias in terms of downstream performance, but runs in a fraction of the time.","tags":null,"title":"Best-First Beam Search","type":"publication"},{"authors":["Shahij Gupta","Pinjia He\"","Clara Meister","Zhendong Su"],"categories":null,"content":"","date":1596240000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596240000,"objectID":"384629e1cca71de45576b3837e4def2c","permalink":"https://cimeister.github.io/publication/guptaal-fse-2020/","publishdate":"2020-04-06T05:47:36.453048Z","relpermalink":"/publication/guptaal-fse-2020/","section":"publication","summary":"Machine translation software has become heavily integrated into our daily lives due to the recent improvement in the performance of deep neural networks. However, machine translation software has been shown to regularly return erroneous translations, which can lead to harmful consequences such as economic loss and political conflicts. Additionally, due to the complexity of the underlying neural models, testing machine translation systems presents new challenges. To address this problem, we introduce a novel methodology called PatInv.  The main intuition behind PatInv is that sentences with different meanings should not have the same translation. Under this general idea, we provide two realizations of PatInv that given an arbitrary sentence, generate syntactically similar but semantically different sentences by: (1) replacing one word in the sentence using a masked language model or (2) removing one word or phrase from the sentence based on its constituency structure. We then test whether the returned translations are the same for the original and modified sentences. We have applied PatInv to test Google Translate and Bing Microsoft Translator using 200 English sentences. Two language settings are considered: English to Hindi (En-Hi) and  English to Chinese (En-Zh). The results show that PatInv can accurately find 308 erroneous translations in Google Translate and 223 erroneous translations in Bing Microsoft Translator, most of which cannot be found by the state-of-the-art approaches.","tags":null,"title":"Machine Translation Testing via Pathological Invariance","type":"publication"},{"authors":["Pinjia He","Clara Meister","Zhendong Su"],"categories":null,"content":"","date":1596240000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596240000,"objectID":"abe3443d10667f8ab3fc5c08adacb115","permalink":"https://cimeister.github.io/publication/heal-icse-2020/","publishdate":"2020-04-06T05:47:36.453048Z","relpermalink":"/publication/heal-icse-2020/","section":"publication","summary":"Machine translation software has increasingly been integrated into our daily lives. People routinely use machine translation for various applications, such as describing symptoms to a foreign doctor and reading political news in a foreign language. However, due to the complexity and intractability of neural machine translation (NMT) models that power modern machine translation systems, these systems are far from being robust. They can return inferior results that lead to misunderstanding, medical misdiagnoses, threats to personal safety, or political conflicts. Despite its apparent importance, validating the robustness of machine translation is very difficult and has, therefore, been much under-explored.\nTo tackle this challenge, we introduce structure-invariant testing (SIT), a novel metamorphic testing approach for validating machine translation software. Our key insight is that the translation results of “similar” source sentences should typically exhibit a similar sentence structure. Specifically, SIT (1) generates similar source sentences by substituting one word in a given sentence with semantically similar, syntactically equivalent words, and (2) represents sentence structure by syntax parse trees (obtained via constituency or dependency parsing). To evaluate SIT, we have used it to test Google Translate and Bing Microsoft Translator with 200 source sentences as input, which led to 64 and 70 buggy translations with 69.5% and 70% top-1 accuracy, respectively. The bugs are diverse, including under-translation, over-translation, incorrect modification, word/phrase mistranslation, and unclear logic, none of which could be detected via existing translation quality metrics.","tags":null,"title":"Structure-Invariant Testing for Machine Translation","type":"publication"},{"authors":["Clara Meister","Elizabeth Salesky","Ryan Cotterell"],"categories":null,"content":"","date":1593561600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593561600,"objectID":"65df8ea6f2757b720fbb48bafcdc38a4","permalink":"https://cimeister.github.io/publication/meisteral-acl-20/","publishdate":"2020-04-06T05:47:36.453048Z","relpermalink":"/publication/meisteral-acl-20/","section":"publication","summary":"Prior work has explored directly regularizing the output distributions of probabilistic models to alleviates peaky (i.e. over-confident) predictions, a common sign of overfitting. This class of techniques, of which label smoothing is one, has a deep mathematical connection to entropy regularization. Despite the consistent success of label smoothing across architectures and data sets in language generation tasks, two problems remain open; (1) there is little understanding of the underlying effects entropy regularizers have on models and (2) the full space of entropy regularization techniques is largely unexplored. We introduce a parametric family of entropy regularizers—which includes label smoothing and the confidence penalty as special cases—and use them to gain a better understanding of the relationship between the entropy of a model’s output distribution and its  performance on language generation tasks. We find that variance in model performance can be explained largely by the resulting entropy of the model’s output distribution rather than by the learning dynamics of the regularizer. Lastly, we find that label smoothing does not allow for sparsity in an output distribution, an undesirable property for language generation models, and therefore advise the use of other entropy regularization methods in its place.","tags":null,"title":"Generalized Entropy Regularization or: There's Nothing Special about Label Smoothing","type":"publication"}]